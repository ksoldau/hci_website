<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>R1</title>
</head>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Katie Soldau - Reading 1</title>
<link href="style.css" rel="stylesheet" type="text/css" />
</head>

<body class="page_readings">
<div class="container">
    <div class="content">
        <div id="top"></div>
        <div class="name">
            <p>K<span class="smaller">ATIE</span> <span class= "taller">S</span><span class="smaller">OLDAU</span> </p>
            <p class="email"> soldau.k@husky.neu.edu </p>
        </div>
        <div class="navigation_bar_container">
            <div class="navigation_bar">
                <ul class="nav_options">
                    <li><a href="index.html">about</a></li>
                    <li><a href="readings.html" class="current">readings</a></li>
                    <li><a href="homework.html">homework</a></li>
                    <li><a href="team_project.html">team project</a><li>

                    <!-- <li><a href="contact.html" class="nav_contact">contact</a></li>-->
                </ul>
            </div>
        </div>
        <!-- for navigation --> 
        
        <div class="reading_nav_container"> 
        <a href="#r1">R1</a>
        <a href="#r2">R2</a>
        </div>
        <div class="readings">     
        <div>
        <h1><div class="h1_text">R1</div></h1>
        <h2>Introduction to HCI</h2>
	<p>There is no agreed upon set of topics that make up the area of human-computer interaction. However, there is a general working definition that goes as follows: “Human-computer interaction is a discipline concerned with the design, evaluation and implementation of interactive computing systems for human use and with the study of major phenomena surrounding them” (<a href="http://old.sigchi.org/cdg/cdg2.html" class="citation">ACM SIGCHI Curricula</a>). A large variety of disciplines are involved in the human-computer interaction area. From a computer science standpoint the focus is specifically on the interaction between one or more humans and one or more computational machines. A machine could be considered a workstation or even a computer embedded in a computational machine, such as a microwave (<a href="http://old.sigchi.org/cdg/cdg2.html" class="citation">ACM SIGCHI Curricula</a>). A human could be considered as a group of humans or an organization. Human-computer interaction arose as a field that was intertwined in its roots from the very beginning. It began during the very early stages in the history of computers as computer graphics emerged as a discipline. In the future, the field will continue to pull from a large number of separate yet intertwined disciplines and will be greatly affected by future technological advancements (<a href="http://old.sigchi.org/cdg/cdg2.html" class="citation">ACM SIGCHI Curricula</a>).</p>
	<p>I think it would be interesting to discuss the future of this field in class. Technology is advancing at a rapid pace, and so anything that might seem far off now may actually be reality of the human-computer interaction area/field upon my graduation. I’m curious as to what the best way would be to prepare yourself for the new advancements, technologies, and discoveries so as to make sure what you’ve learned isn’t obsolete. Something about the reading that I found annoying was that it seemed to repeat the same idea multiple times. It seemed that I read something about human-computer interaction involving multiple disciplines over and over again, when it should have only needed to be stated in the article once or twice for the reader to adequately understand. I also found it annoying (though annoying may be too strong a word) that there was not much talk about what was currently going on in the industry. I felt this way because the reading clearly stated some historical background and future predictions for the subject, but never explicitly stated the current state of the area.</p>

<h2> User-Centered Design </h2> 
	<p>User-Centered Design (UCD) is both a philosophy that places the person at the center of attention, and a process that focuses on cognitive factors. This area of design attempts to answer questions about users and their tasks and goals, then uses those findings to drive development and design (<a href="http://www.stcsig.org/usability/topics/articles/ucd%20_Web_devel.html
" class="citation">Katz-Haas</a>). A big concern of UCD is with usefulness and usability from “everyday things” to software and beyond. Another goal of this type of design is to cut costs while simultaneously increasing user satisfaction and productivity. There are a large number of usability guidelines that are often followed: visibility, memory load, feedback, accessibility, orientation/navigation, errors, satisfaction, legibility, language, and visual design (<a href="http://www.stcsig.org/usability/topics/articles/ucd%20_Web_devel.html
" class="citation">Katz-Haas</a>). In order to develop user-centered web sites it is important to know and involve your users from the beginning while also analyzing their tasks and goals. It’s important to keep in mind that you don’t need to settle on a final direction too soon and to make sure that you repeatedly test for usability (<a href="http://www.stcsig.org/usability/topics/articles/ucd%20_Web_devel.html
" class="citation">Katz-Haas</a>). </p>
	<p> The reading stated that UCD seeks to answer “How do users think this ‘thing’ should work?” I would find this question interesting to discuss in class because I’m curious to know how much nurture vs. nature plays into how a user assumes a ‘thing’ should work. By that I mean whether there are instinctual or common sense ways in which we want or expect something to act, or if those thoughts are solely or mostly just based on past experience with other items. I also think it’d be interesting to find out how those studying this find such information out. I found it confusing that the reading did not mention how to cater to any of your end users who might have a number of disabilities, such as color blindness, blindness, limited mobility, etc. I had assumed that it would play a part in the reading since user-centered design purportedly places the person or user at the center of attention, yet never truly delved into any of the more extreme cases of an end user who might deviate from the norm.</p>
	<p>It seems to me that the difference between user-centered design and human-computer interaction is that UCD is more focused on the user and trying to figure out as much as they can about the user in order to drive development. HCI seems as though it is more concerned with studying how humans and computers interact instead of placing the person/user at the center of attention while designing or implementing interactive computing systems.</p>
<h2>
Kinect </h2>
	<p>The Microsoft Kinect is a 3D sensor that costs $150. Kinect is a hardware made by PrimeSense, an Israeli company. It works by projecting infrared laser patterns onto nearby objects. The laser is then picked up by a dedicated IR sensor to determine the distance for each pixel (<a href="http://spectrum.ieee.org/automaton/robotics/diy/top-10-robotic-kinect-hacks" class="citation">Ackerman</a>). Once all of the distance data has been collected that info is mapped onto an image from a standard RGB (red, green, and blue) camera. The end result is a RGBD image, which means that each pixel has color and distance. The system is capable of mapping out body positions, gestures, motion, and generating 3D maps. Many people have taken these capabilities and used them to add capabilities to robots. Kinect has allowed people to make robots that can autonomously navigate, avoid obstacles, create 3D maps, pretend vacuum, or even control a DaVinci robotic surgical system with your hands (<a href="http://spectrum.ieee.org/automaton/robotics/diy/top-10-robotic-kinect-hacks" class="citation">Ackerman</a>). Other projects people have undertaken include multiple that have taken the information of their body space and movement and then translated that onto a character that inherits all of the motion from the user. This enables users to play virtual games as a character that moves as they do (<a href="http://www.youtube.com/watch?v=8nlk6HhDpDw&list=UUTW58h2zg8r9O0bGmMt2L5Q&index=1
" class="citation">Kinect Projects - The first 5 months</a>). Another interesting project involves interactive puppeteering. The Kinect takes in information of a user’s arm and uses that information to create a virtual puppet that moves according to how the user moves their arm and hand. “Skeletonization code” is run on the silhouette of the user’s arm and tracks the elbow, wrist, fingertips, and thumb. The information gathered from that is then mapped to the movement of the bird puppet (<a href="http://www.youtube.com/watch?v=tAGnSrdOfyA" class="citation">Interactive Puppet Prototype with hacked Kinect</a>). </p>
	<p>I think it would be interesting to discuss exactly how the information taken in by the Kinect can then be translated onto mappings of a virtual character. The puppet YouTube video went into the subject ever so slightly, but I wish I knew more about the workings behind it. I found it interesting and slightly annoying that a lot of the videos I watched had a really similar idea behind the concept: mapping the human motion to a character. While I see how this could add an exciting aspect to a game or other virtual experience, I would’ve liked to see more variety in how developers are using the new technology.  </p>
	<p>I honestly have not seen any other uses for Kinect other than those I saw in the videos as I do not play video games nor am I ever really exposed to them from friends or family. I think that practical applications for the Kinect could be exercise or dance videos, although I’m sure that has been attempted already. Something else that might work is a virtual closet or something of the sort; Kinect scans your body then can show you on the screen with certain clothes of your choosing or even new hair cuts. I could also see it turning some types of physical therapy into a more enjoyable experience that is game-like in nature. This could be useful since it would allow users who have to make sure they get their home physical therapy sessions in to be more motivated to complete what they need to since they may grow to view it as more of a game and less of a chore.</p>
    </div>
        

    <!-- for content --> 
</div>
<!-- for container -->
</body>
</html>
<body>
</body>
</html>
