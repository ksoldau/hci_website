<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Katie Soldau - Readings</title>
<link href="style.css" rel="stylesheet" type="text/css" />
</head>

<body class="page_readings">
<script>
$(document).ready(function() {
	$("a.name").click(function() {
		$("p").toggleClass("name2", 300);
	});
});
</script>
<div class="container">
    <div class="content">
        <div id="top"></div>
        <div class="name">
            <p>K<span class="smaller">ATIE</span> <span class= "taller">S</span><span class="smaller">OLDAU</span> </p>
            <p class="email"> soldau.k@husky.neu.edu </p>
        </div>
        <div class="navigation_bar_container">
            <div class="navigation_bar">
                <ul class="nav_options">
                    <li><a href="index.html">about</a></li>
                    <li><a href="readings.html" class="current">readings</a></li>
                    <li><a href="homework.html">homework</a></li>
                    <li><a href="#">team project</a><li>

                    <!-- <li><a href="contact.html" class="nav_contact">contact</a></li>-->
                </ul>
            </div>
        </div>
        <!-- for navigation --> 
        
        <div class="reading_nav_container"> 
        <a href="#r1">R1</a>
        <a href="#r2">R2</a>
        </div>
        <div class="readings">
        <!-- R2 -->
        <div>
        <h1  id="r2"><div class="h1_text">R2</div></h1>
        <h2>Usability</h2>
        
       <p> User-centered design (UCD) is a process of designing a tool by always keeping in mind how it will be understood by the end user. It is different than designing with a focus on business goals or technological capabilities. User Experience Design (UXD) goes along with this train of thought and can be integrated into UCD. In UXD, research is done with the intended users of a system. This allows human emotions, motivations, and beliefs that surround a task to help shape the design of a user interface.With UCD and UXD, the goal is that instead of users having to adapt to the end system, they will be using a system specifically designed for them, creating a more user-friendly experience (<a href="http://www.usabilityfirst.com/about-usability/introduction-to-user-centered-design/" class="citation">Usability Overview</a>).</p> 

<p>Usability is a qualitative measure of how user-friendly an interactive user interface is; it bridges the gap between a system and its end users. Various interface components correspond to the visual, aural, and haptic channels of the brain. These elements make up the user’s experience and are what usability engineers study. </p>

<p>Usability is important because it can be the difference between successfully performing a task or not; enjoying the process or being frustrated; the success or failure of a system; and productive or unproductive employees. For example, if a website is not highly usable, people will leave and use another readily available site. The usability of a website is imperative to the site’s survival. Usability is so important that it’s now considered best practice to spend 10% of a design project’s budget on it (<a href="http://www.nngroup.com/articles/usability-101-introduction-to-usability/" class="citation">Usability 101</a>). </p>

<p>There are five crucial components that make up usability: learnability, efficiency, memorability, errors, and satisfaction. However, these are not all the important quality attributes; utility is also crucial and is synonymous with a design’s functionality. Combined, usability and utility can dictate whether a system is useful (<a href="http://www.nngroup.com/articles/usability-101-introduction-to-usability/" class="citation">Usability 101</a>).</p>

<p>After analyzing hundreds of usability problems, Jakob Nielsen believes there are <a href="http://www.nngroup.com/articles/ten-usability-heuristics/" class="citation">10 Usability Heuristics</a>. The following ideas are best described as a summary of these heuristics (which are more in the realm of rules of thumb and not concrete guidelines). It’s important that user’s are informed about what’s going on with the system and are able to understand the system. Errors should be prevented as much as possible, but when user’s do make mistakes it should be easy to recover from them without becoming too frustrated. Novice and expert users should be accommodated. Helpful information should be made available, but user’s shouldn’t be burdened with unnecessary information (<a href="http://www.nngroup.com/articles/ten-usability-heuristics/" class="citation">10 Usability Heuristics</a>).</p>

<p>Usability is measured by having representative users of a system participate in usability testing sessions. These sessions involve users having to complete representative tasks using the system without any assistance (<a href="http://www.nngroup.com/articles/usability-101-introduction-to-usability/" class="citation">Usability 101</a>). The researcher records how the user behaviorally and emotionally reacts to the interface. Once testing sessions are complete, the data is analyzed and used by User Experience Engineers to figure out how to improve the interface (<a href="http://www.usabilityfirst.com/about-usability/introduction-to-user-centered-design/" class="citation">Usability Overview</a>).</p>

<p>A number of factors influence the usability of a website or piece of software. However, no matter how skilled a designer is, nothing beats getting information from people who will be using the system. Iterative design is a crucial step in achieving high usability; by progressively refining the design through evaluation at each state, designers and developers can continuously incorporate user and client feedback into the system. </p>

<p>Usability should play a role in every step in the design process. Designer’s should not wait until they have a completed design to test it out. It’s important to test old designs, competitor’s designs, new ideas for designs, and final designs. Conducting field studies, making paper prototypes, and simply making sure to continually check in on the usability of what you’re designing is critical as well. Testing five users is generally enough, and tests can be run in conference rooms that have no distractions. So, although budgets and schedules can prevent this type of approach, it can be feasible with just about process. However, if it can’t be done, testing on system prototypes can help as well (<a href="http://www.usabilityfirst.com/about-usability/introduction-to-user-centered-design/" class="citation">Usability Overview</a>).</p>

<p>In class I think it would be nice to discuss the other possible ways to test for usability, if any. Although I understand how having representative users perform representative tasks on systems could be extremely useful, I’d like to know if there are any other tests that can be done in place of this or to supplement it. I can’t seem to come up with any such ideas on my own, so I’m curious if there are any other helpful approaches. I also would like to talk about how designers’ perception of usability has changed throughout the years and how usability testing has evolved (if at all) with the invention and popularization of new products that have revolutionized the tech industry (such as smart phones).</p>

<p>I found it helpful that most of the general ideas in the readings seem to be timeless. I thought it was important that testing early and often was emphasized because I’m sure that’s something a lot of designers don’t do (I know, personally, I might get slightly irked at having to test so much). For me, it relates to programming; everyone knows they should test their code bit by bit to make sure everything runs correctly, but most people never consistently get around to doing that. Even when people (myself included) know that testing can actually save time, money, and frustration, they tend to set it aside, so I liked that the article continuously brought that up. However, one thing I found odd was that none of the three readings left much room for growth in the idea of usability. Ideas such as making designs easy to navigate or making sure errors are not easy to make seem useful and won’t change, but I still feel as though there might have to be further room for growth in how we test for such qualities. As our technological capabilities (rapidly) expand I think it will be important to discover how best to test for usability in new products.</p>

<h2>The Design of Everyday Things, Chapter 1</h2>
<p>In the first chapter of Donald A. Norman’s book, The Design of Everyday Things, he wonders why people continuously put up with objects that are not easy to figure out how to use, such as many washing machines. If objects are well-designed they should be easy to interpret and understand, often by help from visual clues. Sadly, the world is cluttered with poorly designed devices. </p>

<p>It’s not necessary nor important for the average person to understand how to work extravagant systems but everyday objects should be easy to figure out, such as which way a door swings open. Visibility can help; it is a key principle of design and occurs when correct parts convey the correct message. Natural design is of great assistance as well and ensures that natural signals can be interpreted without conscious thought. (Norman) Lack of visibility can make devices difficult to operate, while excess of visibility does the same. It’s important to find the sweet spot in the middle where what is visible helps indicate how a device is to be used. </p>

<p>There is a psychology of how people interact with everyday things. The affordance of an object is the perception of how it could be used -- ex: a chair is for sitting, knobs are for turning (Norman).  When affordance is accounted for when designing, a user knows what to do just by looking at a device (if the device is simple). Designers’ knowledge of psychology and how things work is important in ensuring time isn’t wasted in learning how to use tens of thousands of everyday objects. People form conceptual models in their minds, built from affordances, constraints, and mappings; it’s important to work with these conceptions. </p>

<p>Norman thinks that the fundamental principles of design involve making things visible in order to form an accurate conceptual model. A good conceptual model indicates a clear relationship between controls and outcomes, but doesn’t need to showcase how such a process works. The system image, or visible part of the device, is responsible for the user’s mental models.</p>

<p>Mapping involves the relationship between an action performed by a user, and the resulting action of the system. Taking advantage of analogies and preconceived notions (often coming from cultural standards) can lead to immediate understanding, but designers have to know that these natural concepts don’t exist for some more-or-less comparisons (Norman). Devices are easy to use when the controls utilize natural mappings and the set of possible options are easily visible. Feedback is also important; it allows the user to know what action was completed and the result.</p>

<p>
I would find it interesting to discuss how the tips given in this chapter, such as the ones dealing with mapping and visibility, can be adapted onto products that are solely digital. This book was written in 1988, a time when computers were much less prevalent in society, and so all of the examples revolve around physical features. I’d like to see how the physical features can translate into virtual or digital ones. I wonder how, for example, the idea of 3D buttons would translate onto a website or mobile phone app; would it make sense to make a virtual 3D button, or come up with an entirely new design?</p>

<p>I found the reading very interesting because it made me think about how every single thing I use each day (and have ever used) had to have been designed at some point. I think it’s also fascinating to think about how we may not even really be conscious of an object’s design when it works extremely well - and that’s the point. When doors are poorly designed, you notice because you get frustrated. However, when doors are designed well, you don’t even notice because you use them as you think you should and they work as you think you should. I wish the reading went further into why bad design is so prevalent in the world around us. I wonder if it’s just because people don’t put the time in to adequately design a product, if people simply don’t know how to produce a well thought out design, or if it has to do with a combination of other factors.</p>

<h2>The Design of Everyday Things, Chapter 2</h2>
<p>In the second chapter of Donald A. Norman’s book, The Design of Everyday Things, he notes that people often blame themselves when they should actually fault the design. Users’ mental models of how objects should work can lead to frustrations if the models do not correspond with reality. This is at no fault of the users; they are just forming models that account for what they can and have perceived. People generally assign casual relations whenever two things occur in succession, even when no relationship actually exists. (cite) This can lead to people believing errors are caused by actions that are actually playing no part. </p>

<p>When designing, it’s important to not bring about learned helplessness, which is when people fail at a task and come to conclusion that they’re incapable. Technology is often a culprit of taught helplessness. Although complex devices may require some instruction, designers should minimize the number and severity of possible errors.</p>

<p>People accomplish tasks in seven stages of action. Goals and intentions are formed, an action is specified and executed, the state of the world is perceived and interpreted, and then the outcome is evaluated. This isn’t a perfect model, but is a general idea of how people function (Norman). Designers must take this into account when designing objects that will be of use. The Gulf of Execution can be helpful as well by measuring how well a system enables a person to perform intended actions. The Gulf of Evaluation is similar but instead reflects on the amount of effort a person must exert in order to understand the physical state of the system and also describes how expectations and intentions have been met (Norman). The gulfs are present in a variety of devices, yet users still blame themselves. Norman believes that each stage of action can be supported by one of one of the four principle’s of good design: visibility, a good conceptual model for the user, good mappings, and feedback. </p>

<p>In class I’d like to talk about how to minimize possibility of user errors. When reading about the topic it seems as though it should be easy enough to do, but I’m sure that’s far from the case. I’d like to know how designers decrease the number of possible errors and also diminish the severity of the errors that can occur. If there are any general design tips or standards used routinely to deal with this it would be interesting to find out about it. </p>

<p>I found this chapter interesting because I had never thought about how being bad at certain devices may not be a fault of the person using said device, but actually a design flaw. I used to have a toaster oven that I had trouble using correctly and I thought it was because I just couldn’t understand what the buttons and knobs did. Now it seems like it could have been more of a design flaw in the product and less of my technological incapabilities that may have played a role. I think this is an important thing to realize and be conscious of because it is a designer’s job to make sure a user can easily operate a product.</p>

<h2>CAPTCHA and reCAPTCHA</h2>
<p>CAPTCHAs are automatically generated tests which humans can pass and (current) computer programs, which write them, cannot.  In fact, programs shouldn’t be able to pass them even if they know the code behind it (<a href="https://www.ccs.neu.edu/course/is4300sp13/ssl/articles/p56-von_ahm.pdf" class="citation">von Ahn, Blum, and Langford</a>).They are generally in the form of colorful images with distorted text at the bottom. </p>

<p>Turing tests are similar to CAPTCHAs in that each test a person and computer to determine who is human. However, in CAPTCHAs, the judge is a computer -- not a human -- and also allows for questions based on a variety of sensory abilities. Online polls and free email services are two areas where CAPTCHAs ensure that bots cannot mess up the process. The test can also ensure that search engines or bots can’t access certain web pages (<a href="https://www.ccs.neu.edu/course/is4300sp13/ssl/articles/p56-von_ahm.pdf" class="citation">von Ahn, Blum, and Langford</a>).</p>

<p>There are a variety of CAPTCHAs. GIMPY, one type, is based on the difficulty of reading text. BONGO requires a user to solve a visual pattern recognition problem. PIX PIX requires users to identify an object in a set of images and is like a CAPTCHA, but cannot be considered one because it would be easy to write a program that could crack it (<a href="https://www.ccs.neu.edu/course/is4300sp13/ssl/articles/p56-von_ahm.pdf" class="citation">von Ahn, Blum, and Langford</a>). Sound-based CAPTCHAs also exist. </p>

<p>CAPTCHAs can help solve the problems previously stated, but have also helped advance the field of AI; either the CAPTCHA remains unbroken and there remains a way to differentiate between humans and computers, or it is broken and a solution to an open AI problem has been found. These Turling-like tests have also proved helpful in an unlikely situation - digitizing books! Although not talked about in the reading, the energy spent by thousands of people solving CAPTCHAs each day is used by <a class="citation" href="http://www.google.com/recaptcha/learnmore
">reCAPTCHA</a> (who was recently acquired by Google) to improve the process of digitizing books. Words that cannot be read by computers are sent to the web (through CAPTCHAs) for humans to decipher. These CAPTCHAs show two words: one which is already known and one which is not. If the user solves the known word, they pass the test. The computer also collects multiple answers about what people think the unknown word is, determine once it’s been deciphered, and use that information to digitize their books.</p>

<p>I think it would be interesting to go into greater detail about why computers cannot (currently) solve CAPTCHAs and how Malik and Mori discovered an algorithm that worked 80% of the time. I know nothing about how the code for CAPTCHAs works, so it would be interesting to delve further into it. Something else I thought was interesting was how Turing Tests and CAPTCHAs are related. I’d only heard about Turing Tests in vague concepts before, so it was neat to see both concepts explained and examined together. </p>

<p>Something that works well with CAPTCHAs is that when encountering them, I feel as though the site or service that I’m about to use is secure (regardless of how accurate that is). I also think that the time needed to pass the test is not so long as to cause any sort of perceived large inconvenience. The ability to refresh the CAPTCHA to get a different image is useful as well, since I’d say about half the time I can’t make out what the letters or numbers are. However, needing to use the refresh button is the biggest problem I’ve had with CAPTCHAs. The letters or numbers are frequently too smushed together for me to accurately make them out. I would improve CATPCHAs by somehow making them easier to read - I know nothing of the code used so could offer no insight how to do so, but maybe simply making the image bigger would help a great deal. </p>
</div>
<!-- end of R2 -->


        
        <div>
        <h1 id="r1"><div class="h1_text">R1</div></h1>
        <h2>Introduction to HCI</h2>
	<p>There is no agreed upon set of topics that make up the area of human-computer interaction. However, there is a general working definition that goes as follows: “Human-computer interaction is a discipline concerned with the design, evaluation and implementation of interactive computing systems for human use and with the study of major phenomena surrounding them” (<a href="http://old.sigchi.org/cdg/cdg2.html" class="citation">ACM SIGCHI Curricula</a>). A large variety of disciplines are involved in the human-computer interaction area. From a computer science standpoint the focus is specifically on the interaction between one or more humans and one or more computational machines. A machine could be considered a workstation or even a computer embedded in a computational machine, such as a microwave (<a href="http://old.sigchi.org/cdg/cdg2.html" class="citation">ACM SIGCHI Curricula</a>). A human could be considered as a group of humans or an organization. Human-computer interaction arose as a field that was intertwined in its roots from the very beginning. It began during the very early stages in the history of computers as computer graphics emerged as a discipline. In the future, the field will continue to pull from a large number of separate yet intertwined disciplines and will be greatly affected by future technological advancements (<a href="http://old.sigchi.org/cdg/cdg2.html" class="citation">ACM SIGCHI Curricula</a>).</p>
	<p>I think it would be interesting to discuss the future of this field in class. Technology is advancing at a rapid pace, and so anything that might seem far off now may actually be reality of the human-computer interaction area/field upon my graduation. I’m curious as to what the best way would be to prepare yourself for the new advancements, technologies, and discoveries so as to make sure what you’ve learned isn’t obsolete. Something about the reading that I found annoying was that it seemed to repeat the same idea multiple times. It seemed that I read something about human-computer interaction involving multiple disciplines over and over again, when it should have only needed to be stated in the article once or twice for the reader to adequately understand. I also found it annoying (though annoying may be too strong a word) that there was not much talk about what was currently going on in the industry. I felt this way because the reading clearly stated some historical background and future predictions for the subject, but never explicitly stated the current state of the area.</p>

<h2> User-Centered Design </h2> 
	<p>User-Centered Design (UCD) is both a philosophy that places the person at the center of attention, and a process that focuses on cognitive factors. This area of design attempts to answer questions about users and their tasks and goals, then uses those findings to drive development and design (<a href="http://www.stcsig.org/usability/topics/articles/ucd%20_Web_devel.html
" class="citation">Katz-Haas</a>). A big concern of UCD is with usefulness and usability from “everyday things” to software and beyond. Another goal of this type of design is to cut costs while simultaneously increasing user satisfaction and productivity. There are a large number of usability guidelines that are often followed: visibility, memory load, feedback, accessibility, orientation/navigation, errors, satisfaction, legibility, language, and visual design (<a href="http://www.stcsig.org/usability/topics/articles/ucd%20_Web_devel.html
" class="citation">Katz-Haas</a>). In order to develop user-centered web sites it is important to know and involve your users from the beginning while also analyzing their tasks and goals. It’s important to keep in mind that you don’t need to settle on a final direction too soon and to make sure that you repeatedly test for usability (<a href="http://www.stcsig.org/usability/topics/articles/ucd%20_Web_devel.html
" class="citation">Katz-Haas</a>). </p>
	<p> The reading stated that UCD seeks to answer “How do users think this ‘thing’ should work?” I would find this question interesting to discuss in class because I’m curious to know how much nurture vs. nature plays into how a user assumes a ‘thing’ should work. By that I mean whether there are instinctual or common sense ways in which we want or expect something to act, or if those thoughts are solely or mostly just based on past experience with other items. I also think it’d be interesting to find out how those studying this find such information out. I found it confusing that the reading did not mention how to cater to any of your end users who might have a number of disabilities, such as color blindness, blindness, limited mobility, etc. I had assumed that it would play a part in the reading since user-centered design purportedly places the person or user at the center of attention, yet never truly delved into any of the more extreme cases of an end user who might deviate from the norm.</p>
	<p>It seems to me that the difference between user-centered design and human-computer interaction is that UCD is more focused on the user and trying to figure out as much as they can about the user in order to drive development. HCI seems as though it is more concerned with studying how humans and computers interact instead of placing the person/user at the center of attention while designing or implementing interactive computing systems.</p>
<h2>
Kinect </h2>
	<p>The Microsoft Kinect is a 3D sensor that costs $150. Kinect is a hardware made by PrimeSense, an Israeli company. It works by projecting infrared laser patterns onto nearby objects. The laser is then picked up by a dedicated IR sensor to determine the distance for each pixel (<a href="http://spectrum.ieee.org/automaton/robotics/diy/top-10-robotic-kinect-hacks" class="citation">Ackerman</a>). Once all of the distance data has been collected that info is mapped onto an image from a standard RGB (red, green, and blue) camera. The end result is a RGBD image, which means that each pixel has color and distance. The system is capable of mapping out body positions, gestures, motion, and generating 3D maps. Many people have taken these capabilities and used them to add capabilities to robots. Kinect has allowed people to make robots that can autonomously navigate, avoid obstacles, create 3D maps, pretend vacuum, or even control a DaVinci robotic surgical system with your hands (<a href="http://spectrum.ieee.org/automaton/robotics/diy/top-10-robotic-kinect-hacks" class="citation">Ackerman</a>). Other projects people have undertaken include multiple that have taken the information of their body space and movement and then translated that onto a character that inherits all of the motion from the user. This enables users to play virtual games as a character that moves as they do (<a href="http://www.youtube.com/watch?v=8nlk6HhDpDw&list=UUTW58h2zg8r9O0bGmMt2L5Q&index=1
" class="citation">Kinect Projects - The first 5 months</a>). Another interesting project involves interactive puppeteering. The Kinect takes in information of a user’s arm and uses that information to create a virtual puppet that moves according to how the user moves their arm and hand. “Skeletonization code” is run on the silhouette of the user’s arm and tracks the elbow, wrist, fingertips, and thumb. The information gathered from that is then mapped to the movement of the bird puppet (<a href="http://www.youtube.com/watch?v=tAGnSrdOfyA" class="citation">Interactive Puppet Prototype with hacked Kinect</a>). </p>
	<p>I think it would be interesting to discuss exactly how the information taken in by the Kinect can then be translated onto mappings of a virtual character. The puppet YouTube video went into the subject ever so slightly, but I wish I knew more about the workings behind it. I found it interesting and slightly annoying that a lot of the videos I watched had a really similar idea behind the concept: mapping the human motion to a character. While I see how this could add an exciting aspect to a game or other virtual experience, I would’ve liked to see more variety in how developers are using the new technology.  </p>
	<p>I honestly have not seen any other uses for Kinect other than those I saw in the videos as I do not play video games nor am I ever really exposed to them from friends or family. I think that practical applications for the Kinect could be exercise or dance videos, although I’m sure that has been attempted already. Something else that might work is a virtual closet or something of the sort; Kinect scans your body then can show you on the screen with certain clothes of your choosing or even new hair cuts. I could also see it turning some types of physical therapy into a more enjoyable experience that is game-like in nature. This could be useful since it would allow users who have to make sure they get their home physical therapy sessions in to be more motivated to complete what they need to since they may grow to view it as more of a game and less of a chore.</p>
    </div>
        
        </div>
        <a class="citation back_to_top" href="#top">back to top</a>
        
    </div>
    <!-- for content --> 
</div>
<!-- for container -->
</body>
</html>